{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "wIsPFQ_5U9gb",
    "outputId": "8837f21b-38a2-4522-b911-d15ed2f4f8d8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n    - Text Classification\\n    - Token Classification\\n    - Table Question Answering\\n    - Question Answering\\n    - Zero-Shot Classification\\n    - Translation\\n    - Summarization\\n    - Feature Extraction\\n    - Text Generation\\n    - Text2Text Generation\\n    - Fill-Mask\\n    - Sentence Similarity\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Basic llm - text\n",
    "\n",
    "'''\n",
    "    - Text Classification\n",
    "    - Token Classification\n",
    "    - Table Question Answering\n",
    "    - Question Answering\n",
    "    - Zero-Shot Classification\n",
    "    - Translation\n",
    "    - Summarization\n",
    "    - Feature Extraction\n",
    "    - Text Generation\n",
    "    - Text2Text Generation\n",
    "    - Fill-Mask\n",
    "    - Sentence Similarity\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1PdlsQCXgyP",
    "outputId": "146d991d-3d91-47f7-c92b-d77cf5b92490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34rrVvqJo8PH"
   },
   "source": [
    "# **Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4H_Kw5DVTxW",
    "outputId": "acabfabb-8b7c-419c-9109-49e686fa1542"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.7235766649246216}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)\n",
    "sentiment_task(\"Covid cases are increasing fast!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7wNikufocz_",
    "outputId": "62c5db5d-ca93-486a-fc3e-f11bf64380bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Covid cases are increasing fast!\n",
      "Sentiment: negative, Score: 0.7235766649246216\n",
      "\n",
      "Text: The vaccine rollout is going smoothly.\n",
      "Sentiment: positive, Score: 0.8173474073410034\n",
      "\n",
      "Text: I'm feeling anxious about the future.\n",
      "Sentiment: negative, Score: 0.7313439249992371\n",
      "\n",
      "Text: The new policy has received mixed reactions.\n",
      "Sentiment: negative, Score: 0.5935551524162292\n",
      "\n",
      "Text: Stock markets are hitting new highs!\n",
      "Sentiment: positive, Score: 0.9623121619224548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the pipeline function from the transformers library\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the model and tokenizer to be used for sentiment analysis\n",
    "model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "# Load the sentiment-analysis pipeline with the specified model and tokenizer\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "# Define a list of texts for sentiment analysis\n",
    "texts = [\n",
    "    \"Covid cases are increasing fast!\",\n",
    "    \"The vaccine rollout is going smoothly.\",\n",
    "    \"I'm feeling anxious about the future.\",\n",
    "    \"The new policy has received mixed reactions.\",\n",
    "    \"Stock markets are hitting new highs!\"\n",
    "]\n",
    "\n",
    "# Perform sentiment analysis on each text in the list\n",
    "results = sentiment_task(texts)\n",
    "\n",
    "# Print the results\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result['label']}, Score: {result['score']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNy0DlwbrEWM"
   },
   "source": [
    "# **Text Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnok6KFlVaeq",
    "outputId": "fdeb2aa7-1051-4f5a-acf4-ea504adc3808"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.6925845742225647}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classification = pipeline(\"text-classification\", model=model_name)\n",
    "text_classification(\"Brevity is the soul of wit.\", top_k=1, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnM8ykQN20c4"
   },
   "source": [
    "# **Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d-6jAssWBgg",
    "outputId": "4e2d891e-4a2c-42bd-e652-4ccd834e39ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'An attention mechanism is an Encoder-Decoder kind of neural network architecture that allows the model to focus on specific sections of the input. It dynamically assigns weights to different elements in the input, indicating their relative importance or relevance. By incorporating attention, the model can selectively attend to and process the most relevant information.'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\" An attention mechanism is an Encoder-Decoder kind of neural network architecture that allows the model to focus on specific sections of the input\n",
    "while executing a task. It dynamically assigns weights to different elements in the input, indicating their relative importance or relevance.\n",
    "By incorporating attention, the model can selectively attend to and process the most relevant information, capturing dependencies and relationships within the data. This mechanism is particularly valuable in tasks involving sequential or structured data, such as natural language processing or computer vision, as it enables the model to effectively handle long-range dependencies and improve performance by selectively attending to important features or contexts.\n",
    "Recurrent models of visual attention use reinforcement learning to focus attention on key areas of the image.\n",
    "A recurrent neural network governs the peek network, which dynamically selects particular locations for exploration over time. In classification tasks, this method outperforms convolutional neural networks. Additionally, this framework goes beyond image identification and may be used for a variety of visual reinforcement learning applications, such as helping robots choose behaviours to accomplish particular goals. Although the most basic use of this strategy is supervised learning, the use of reinforcement learning permits more adaptable and flexible decision-making based on feedback from past glances and rewards earned throughout the learning process.\n",
    "The application of attention mechanisms to image captioning has substantially enhanced the quality and accuracy of generated captions.\n",
    "By incorporating attention, the model learns to focus on pertinent image regions while creating each caption word. The model can synchronize the visual and\n",
    "textual modalities by paying attention to various areas of the image at each time step thanks to the attention mechanism. By focusing on important objects or\n",
    "areas in the image, the model is able to produce captions that are more detailed and contextually appropriate. The attention-based image captioning models have\n",
    "proven to perform better at catching minute details, managing complicated scenes, and delivering cohesive and educational captions that closely match the visual\n",
    "material.\n",
    "The attention mechanism is a technique used in machine learning and natural language processing to increase model accuracy by focusing on relevant data.\n",
    "It enables the model to focus on certain areas of the input data, giving more weight to crucial features and disregarding unimportant ones.\n",
    "Each input attribute is given a weight based on how important it is to the output in order to accomplish this. T\n",
    "he performance of tasks requiring the utilization of the attention mechanism has significantly improved in areas including speech recognition, image captioning,\n",
    "and machine translation.\n",
    "\"\"\"\n",
    "summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phHCU--T2_YT"
   },
   "source": [
    "# **Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "9be3a8125ae947bf830cd664f6507e1f",
      "481ce43f81e449d18ce4a65b78be13c4",
      "b48e0f12879046e8b37f53674991c04d",
      "b21f8a20dc8e48c3ab5e793b964feb2b",
      "1c14102059e7401ba7139d59ec8d2ee1",
      "ba59990bf1b147d1b0b356456a821b90",
      "f89793fdcff44843ab4d53f09d89a8d4",
      "6c5ce41abaa54460a78adbf9ba5c1fb8",
      "edda4e059df842db8240ab4ee190801e",
      "b89b94f23eeb40b6b21d0e504e985eb9",
      "a26b8631ce924dfc8b05daeccee39e03"
     ]
    },
    "id": "yfSHlTeOWT3n",
    "outputId": "9845e225-1202-43d4-d091-69707828eefa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be3a8125ae947bf830cd664f6507e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tell me joke on AI and I'll tell you the future of humanity.\n",
      "AI: What do you call a fish wearing a bowtie? Sofishticated.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer('''tell me joke on AI''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COmrzIXF3rGJ"
   },
   "source": [
    "# **Question Answering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FaR7CYF4XICG",
    "outputId": "c027c3c2-a460-4076-b71a-8f39e89e7c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6407183408737183, 'start': 68, 'end': 93, 'answer': 'Pandavas and the Kauravas'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Who were the main opponents in the Kurukshetra War?',\n",
    "    'context': '''In the epic Mahabharata, the Kurukshetra War was fought between the Pandavas and the Kauravas,\n",
    "                two groups of cousins vying for control over the kingdom of Hastinapur.\n",
    "                The war is considered one of the greatest conflicts in Hindu mythology and is filled with tales of valor, betrayal, and divine intervention.'''\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-QP1w8R5siF"
   },
   "source": [
    "# **Sentence Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVfPvX7rXeqT",
    "outputId": "782031f0-106f-4b13-ece2-1388c1c4567c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76568970e-02  6.34959117e-02  4.87130918e-02  7.93050230e-02\n",
      "   3.74480747e-02  2.65279436e-03  3.93749438e-02 -7.09848432e-03\n",
      "   5.93614280e-02  3.15369926e-02  6.00981042e-02 -5.29051460e-02\n",
      "   4.06067558e-02 -2.59308219e-02  2.98427958e-02  1.12691114e-03\n",
      "   7.35148489e-02 -5.03819361e-02 -1.22386679e-01  2.37028319e-02\n",
      "   2.97265444e-02  4.24768254e-02  2.56337877e-02  1.99520565e-03\n",
      "  -5.69190606e-02 -2.71598026e-02 -3.29035372e-02  6.60248473e-02\n",
      "   1.19007148e-01 -4.58791070e-02 -7.26214498e-02 -3.25840004e-02\n",
      "   5.23413233e-02  4.50552516e-02  8.25298857e-03  3.67024243e-02\n",
      "  -1.39415581e-02  6.53918907e-02 -2.64272466e-02  2.06395169e-04\n",
      "  -1.36643248e-02 -3.62810083e-02 -1.95043702e-02 -2.89738569e-02\n",
      "   3.94270606e-02 -8.84090886e-02  2.62426864e-03  1.36714159e-02\n",
      "   4.83063236e-02 -3.11565809e-02 -1.17329165e-01 -5.11690192e-02\n",
      "  -8.85288119e-02 -2.18962226e-02  1.42986514e-02  4.44167741e-02\n",
      "  -1.34815481e-02  7.43392855e-02  2.66382564e-02 -1.98762584e-02\n",
      "   1.79191586e-02 -1.06052440e-02 -9.04263481e-02  2.13269163e-02\n",
      "   1.41204879e-01 -6.47176523e-03 -1.40387670e-03 -1.53609905e-02\n",
      "  -8.73571932e-02  7.22173974e-02  2.01403257e-02  4.25587483e-02\n",
      "  -3.49014178e-02  3.19592305e-04 -8.02970678e-02 -3.27472501e-02\n",
      "   2.85268333e-02 -5.13658039e-02  1.09389201e-01  8.19328055e-02\n",
      "  -9.84039977e-02 -9.34095159e-02 -1.51292318e-02  4.51248437e-02\n",
      "   4.94171903e-02 -2.51867864e-02  1.57077648e-02 -1.29290745e-01\n",
      "   5.31891827e-03  4.02347278e-03 -2.34572385e-02 -6.72983229e-02\n",
      "   2.92280912e-02 -2.60845143e-02  1.30625218e-02 -3.11663207e-02\n",
      "  -4.82713804e-02 -5.58859669e-02 -3.87505181e-02  1.20010786e-01\n",
      "  -1.03924414e-02  4.89705093e-02  5.53537346e-02  4.49358933e-02\n",
      "  -4.00971295e-03 -1.02959760e-01 -2.92968564e-02 -5.83402514e-02\n",
      "   2.70472169e-02 -2.20169183e-02 -7.22241253e-02 -4.13869806e-02\n",
      "  -1.93297733e-02  2.73331744e-03  2.76904262e-04 -9.67588350e-02\n",
      "  -1.00574747e-01 -1.41922766e-02 -8.07892084e-02  4.53925505e-02\n",
      "   2.45041121e-02  5.97614050e-02 -7.38185421e-02  1.19843744e-02\n",
      "  -6.63403496e-02 -7.69044608e-02  3.85158062e-02 -5.59362183e-33\n",
      "   2.80013699e-02 -5.60785122e-02 -4.86601740e-02  2.15570033e-02\n",
      "   6.01980723e-02 -4.81403358e-02 -3.50247324e-02  1.93313900e-02\n",
      "  -1.75151993e-02 -3.89209688e-02 -3.81061714e-03 -1.70287769e-02\n",
      "   2.82099545e-02  1.28290886e-02  4.71601002e-02  6.21029735e-02\n",
      "  -6.43588826e-02  1.29285663e-01 -1.31230848e-02  5.23069501e-02\n",
      "  -3.73680852e-02  2.89094448e-02 -1.68981329e-02 -2.37330385e-02\n",
      "  -3.33491974e-02 -5.16762845e-02  1.55356796e-02  2.08802614e-02\n",
      "  -1.25371115e-02  4.59578894e-02  3.72720510e-02  2.80567203e-02\n",
      "  -5.90005741e-02 -1.16988290e-02  4.92182523e-02  4.70328815e-02\n",
      "   7.35487491e-02 -3.70530002e-02  3.98462638e-03  1.06412554e-02\n",
      "  -1.61533040e-04 -5.27166426e-02  2.75927763e-02 -3.92921977e-02\n",
      "   8.44717771e-02  4.86860760e-02 -4.85872431e-03  1.79948341e-02\n",
      "  -4.28570434e-02  1.23375617e-02  6.39958074e-03  4.04823050e-02\n",
      "   1.48887346e-02 -1.53941168e-02  7.62947872e-02  2.37043202e-02\n",
      "   4.45237532e-02  5.08195162e-02 -2.31253658e-03 -1.88737400e-02\n",
      "  -1.23335840e-02  4.66001816e-02 -5.63438497e-02  6.29927516e-02\n",
      "  -3.15534957e-02  3.24912108e-02  2.34673265e-02 -6.55438080e-02\n",
      "   2.01709457e-02  2.57082544e-02 -1.23868762e-02 -8.36494938e-03\n",
      "  -6.64377660e-02  9.43073630e-02 -3.57092693e-02 -3.42483446e-02\n",
      "  -6.66354876e-03 -8.01527407e-03 -3.09710894e-02  4.33011726e-02\n",
      "  -8.21396243e-03 -1.50795057e-01  3.07692196e-02  4.00718674e-02\n",
      "  -3.79293747e-02  1.93215464e-03  4.00530808e-02 -8.77075195e-02\n",
      "  -3.68491784e-02  8.57952889e-03 -3.19252238e-02 -1.25258043e-02\n",
      "   7.35539421e-02  1.34738290e-03  2.05918942e-02  2.71098091e-33\n",
      "  -5.18577360e-02  5.78360558e-02 -9.18985531e-02  3.94421890e-02\n",
      "   1.05576538e-01 -1.96912140e-02  6.18402548e-02 -7.63464794e-02\n",
      "   2.40880549e-02  9.40048620e-02 -1.16535470e-01  3.71198356e-02\n",
      "   5.22424765e-02 -3.95852840e-03  5.72214313e-02  5.32855280e-03\n",
      "   1.24016829e-01  1.39022581e-02 -1.10249929e-02  3.56053226e-02\n",
      "  -3.30754966e-02  8.16574097e-02 -1.52003355e-02  6.05585463e-02\n",
      "  -6.01397380e-02  3.26102711e-02 -3.48296873e-02 -1.69881918e-02\n",
      "  -9.74907875e-02 -2.71483548e-02  1.74708827e-03 -7.68982470e-02\n",
      "  -4.31858227e-02 -1.89985335e-02 -2.91661173e-02  5.77488728e-02\n",
      "   2.41821744e-02 -1.16902012e-02 -6.21435083e-02  2.84351762e-02\n",
      "  -2.37511209e-04 -2.51783505e-02  4.39636922e-03  8.12840387e-02\n",
      "   3.64184417e-02 -6.04006387e-02 -3.65517363e-02 -7.93748200e-02\n",
      "  -5.08530019e-03  6.69699088e-02 -1.17784373e-01  3.23743783e-02\n",
      "  -4.71252128e-02 -1.34459753e-02 -9.48445052e-02  8.24950729e-03\n",
      "  -1.06748622e-02 -6.81881979e-02  1.11815217e-03  2.48020366e-02\n",
      "  -6.35889322e-02  2.84492839e-02 -2.61303484e-02  8.58110934e-02\n",
      "   1.14682287e-01 -5.35345897e-02 -5.63588403e-02  4.26008850e-02\n",
      "   1.09453816e-02  2.09579542e-02  1.00131221e-01  3.26051526e-02\n",
      "  -1.84208781e-01 -3.93208824e-02 -6.91455081e-02 -6.38104975e-02\n",
      "  -6.56386241e-02 -6.41253125e-03 -4.79612723e-02 -7.68133104e-02\n",
      "   2.95384582e-02 -2.29948610e-02  4.17036898e-02 -2.50047781e-02\n",
      "  -4.54509491e-03 -4.17136922e-02 -1.32289464e-02 -6.38357773e-02\n",
      "  -2.46474426e-03 -1.37337632e-02  1.68976597e-02 -6.30398169e-02\n",
      "   8.98880810e-02  4.18170542e-02 -1.85687244e-02 -1.80442150e-08\n",
      "  -1.67998262e-02 -3.21577974e-02  6.30383566e-02 -4.13092375e-02\n",
      "   4.44819294e-02  2.02467199e-03  6.29592836e-02 -5.17373858e-03\n",
      "  -1.00444146e-02 -3.05640474e-02  3.52672450e-02  5.58581762e-02\n",
      "  -4.67124805e-02  3.45102809e-02  3.29578109e-02  4.30114381e-02\n",
      "   2.94361450e-02 -3.03164367e-02 -1.71107650e-02  7.37484992e-02\n",
      "  -5.47909662e-02  2.77515519e-02  6.20164815e-03  1.58800669e-02\n",
      "   3.42978574e-02 -5.15752612e-03  2.35079750e-02  7.53135607e-02\n",
      "   1.92843601e-02  3.36197019e-02  5.09103723e-02  1.52497083e-01\n",
      "   1.64207723e-02  2.70528588e-02  3.75162363e-02  2.18553655e-02\n",
      "   5.66334166e-02 -3.95747237e-02  7.12313652e-02 -5.41377217e-02\n",
      "   1.03770138e-03  2.11853217e-02 -3.56308892e-02  1.09017000e-01\n",
      "   2.76521919e-03  3.13997604e-02  1.38418679e-03 -3.45738418e-02\n",
      "  -4.59277704e-02  2.88083404e-02  7.16908183e-03  4.84685265e-02\n",
      "   2.61018425e-02 -9.44075920e-03  2.82169394e-02  3.48723978e-02\n",
      "   3.69098634e-02 -8.58948193e-03 -3.53205539e-02 -2.47856844e-02\n",
      "  -1.91921014e-02  3.80707867e-02  5.99653944e-02 -4.22286987e-02]\n",
      " [ 8.64385739e-02  1.02762617e-01  5.39454632e-03  2.04443582e-03\n",
      "  -9.96339321e-03  2.53854990e-02  4.92875986e-02 -3.06265987e-02\n",
      "   6.87254891e-02  1.01365978e-02  7.75397569e-02 -9.00806785e-02\n",
      "   6.10614289e-03 -5.69898523e-02  1.41715044e-02  2.80491523e-02\n",
      "  -8.68464485e-02  7.64399171e-02 -1.03491277e-01 -6.77437931e-02\n",
      "   6.99946955e-02  8.44251141e-02 -7.24916160e-03  1.04770577e-02\n",
      "   1.34020438e-02  6.77576587e-02 -9.42086279e-02 -3.71690169e-02\n",
      "   5.22617549e-02 -3.10853589e-02 -9.63406563e-02  1.57716926e-02\n",
      "   2.57866643e-02  7.85244778e-02  7.89949372e-02  1.91516541e-02\n",
      "   1.64356530e-02  3.10084783e-03  3.81311588e-02  2.37090662e-02\n",
      "   1.05389701e-02 -4.40645032e-02  4.41738181e-02 -2.58727595e-02\n",
      "   6.15378767e-02 -4.05427739e-02 -8.64140317e-02  3.19722444e-02\n",
      "  -8.90679832e-04 -2.44436748e-02 -9.19721127e-02  2.33939346e-02\n",
      "  -8.30293298e-02  4.41510379e-02 -2.49692928e-02  6.23020045e-02\n",
      "  -1.30351877e-03  7.51395151e-02  2.46385150e-02 -6.47244304e-02\n",
      "  -1.17727771e-01  3.83392163e-02 -9.11767557e-02  6.35446310e-02\n",
      "   7.62739554e-02 -8.80241096e-02  9.54557583e-03 -4.69717719e-02\n",
      "  -8.41740668e-02  3.88823412e-02 -1.14393584e-01  6.28861133e-03\n",
      "  -3.49361561e-02  2.39750724e-02 -3.31317075e-02 -1.57244261e-02\n",
      "  -3.78955491e-02 -8.81248619e-03  7.06118718e-02  3.28066535e-02\n",
      "   2.03674473e-03 -1.12278953e-01  6.79721124e-03  1.22765303e-02\n",
      "   3.35303582e-02 -1.36200646e-02 -2.25490239e-02 -2.25228686e-02\n",
      "  -2.03194469e-02  5.04297428e-02 -7.48652741e-02 -8.22822079e-02\n",
      "   7.65962601e-02  4.93392199e-02 -3.75553481e-02  1.44634657e-02\n",
      "  -5.72457500e-02 -1.79954320e-02  1.09697975e-01  1.19462773e-01\n",
      "   8.09236255e-04  6.17057718e-02  3.26322839e-02 -1.30780131e-01\n",
      "  -1.48636624e-01 -6.16233014e-02  4.33885902e-02  2.67129131e-02\n",
      "   1.39785931e-02 -3.94002460e-02 -2.52711605e-02  3.87741649e-03\n",
      "   3.58664803e-02 -6.15420528e-02  3.76660563e-02  2.67564990e-02\n",
      "  -3.82659249e-02 -3.54793221e-02 -2.39227470e-02  8.67977515e-02\n",
      "  -1.84063241e-02  7.71039575e-02  1.39863882e-03  7.00383186e-02\n",
      "  -4.77878004e-02 -7.89820105e-02  5.10814264e-02 -2.99868407e-33\n",
      "  -3.91646065e-02 -2.56207655e-03  1.65210515e-02  9.48941894e-03\n",
      "  -5.66219278e-02  6.57782853e-02 -4.77002673e-02  1.11661730e-02\n",
      "  -5.73558174e-02 -9.16258618e-03 -2.17521153e-02 -5.59531711e-02\n",
      "  -1.11422781e-02  9.32793319e-02  1.66765060e-02 -1.36723649e-02\n",
      "   4.34388630e-02  1.87246769e-03  7.29950238e-03  5.16332164e-02\n",
      "   4.80608679e-02  1.35341510e-01 -1.71739180e-02 -1.29698263e-02\n",
      "  -7.50109777e-02  2.61107814e-02  2.69801989e-02  7.83055846e-04\n",
      "  -4.87270132e-02  1.17842685e-02 -4.59580421e-02 -4.83213514e-02\n",
      "  -1.95671190e-02  1.93889178e-02  1.98807158e-02  1.67432185e-02\n",
      "   9.87801179e-02 -2.74087843e-02  2.34808773e-02  3.70229827e-03\n",
      "  -6.14514500e-02 -1.21231191e-03 -9.50472988e-03  9.25154984e-03\n",
      "   2.38443594e-02  8.61231908e-02  2.26789974e-02  5.45112416e-04\n",
      "   3.47130150e-02  6.25457708e-03 -6.92774775e-03  3.92400548e-02\n",
      "   1.15674753e-02  3.26279812e-02  6.22155704e-02  2.76114345e-02\n",
      "   1.86883714e-02  3.55805606e-02  4.11796011e-02  1.54781919e-02\n",
      "   4.22691554e-02  3.82248312e-02  1.00313211e-02 -2.83245947e-02\n",
      "   4.47052233e-02 -4.10459153e-02 -4.50545410e-03 -5.44734336e-02\n",
      "   2.62321196e-02  1.79862324e-02 -1.23118773e-01 -4.66952063e-02\n",
      "  -1.35913379e-02  6.46710098e-02  3.57350823e-03 -1.22234114e-02\n",
      "  -1.79382414e-02 -2.55502276e-02  2.37224251e-02  4.08666627e-03\n",
      "  -6.51475564e-02  4.43651825e-02  4.68595996e-02 -3.25174816e-02\n",
      "   4.02272865e-03 -3.97601072e-03  1.11939581e-02 -9.95597616e-02\n",
      "   3.33168209e-02  8.01060945e-02  9.42692310e-02 -6.38293922e-02\n",
      "   3.23151536e-02 -5.13553396e-02 -7.49876909e-03  5.30048862e-34\n",
      "  -4.13194895e-02  9.49646086e-02 -1.06401429e-01  4.96590808e-02\n",
      "  -3.41913551e-02 -3.16745788e-02 -1.71556100e-02  1.70103775e-03\n",
      "   5.79758063e-02 -1.21775211e-03 -1.68536119e-02 -5.16912937e-02\n",
      "   5.52998744e-02 -3.42647359e-02  3.08179185e-02 -3.10481023e-02\n",
      "   9.27532613e-02  3.72663587e-02 -2.37397756e-02  4.45893705e-02\n",
      "   1.46153728e-02  1.16239339e-01 -5.00112586e-02  3.88716534e-02\n",
      "   4.24749963e-03  2.56976299e-02  3.27243842e-02  4.29907814e-02\n",
      "  -1.36144347e-02  2.56122164e-02  1.06262127e-02 -8.46864209e-02\n",
      "  -9.52982232e-02  1.08399868e-01 -7.51600191e-02 -1.37773901e-02\n",
      "   6.37337789e-02 -4.49667964e-03 -3.25321332e-02  6.23614155e-02\n",
      "   3.48052904e-02 -3.54922116e-02 -2.00222451e-02  3.66608277e-02\n",
      "  -2.48837005e-02  1.01819010e-02 -7.01233000e-02 -4.31950912e-02\n",
      "   2.95332521e-02 -2.94988276e-04 -3.45386416e-02  1.46675594e-02\n",
      "  -9.83970016e-02 -4.70488481e-02 -8.85495450e-03 -8.89914259e-02\n",
      "   3.50995772e-02 -1.29602015e-01 -4.98866066e-02 -6.12047240e-02\n",
      "  -5.97797073e-02  9.46319476e-03  4.91217598e-02 -7.75026754e-02\n",
      "   8.09727013e-02 -4.79257442e-02  2.34377175e-03  7.57030994e-02\n",
      "  -2.40176041e-02 -1.52546046e-02  4.86738756e-02 -3.85968834e-02\n",
      "  -7.04831704e-02 -1.20348213e-02 -3.88790257e-02 -7.76016787e-02\n",
      "  -1.07243676e-02  1.04187904e-02 -2.13753730e-02 -9.17386413e-02\n",
      "  -1.11344876e-02 -2.96066068e-02  2.46458091e-02  4.65713115e-03\n",
      "  -1.63449887e-02 -3.95219736e-02  7.73373991e-02 -2.84733027e-02\n",
      "  -3.69940838e-03  8.27665105e-02 -1.10408897e-02  3.13983597e-02\n",
      "   5.35094254e-02  5.75145856e-02 -3.17622162e-02 -1.52911284e-08\n",
      "  -7.99661428e-02 -4.76797074e-02 -8.59788731e-02  5.69616482e-02\n",
      "  -4.08866294e-02  2.23832354e-02 -4.64445213e-03 -3.80131193e-02\n",
      "  -3.10671050e-02 -1.07278246e-02  1.97698642e-02  7.76997488e-03\n",
      "  -6.09475328e-03 -3.86376120e-02  2.80271955e-02  6.78138137e-02\n",
      "  -2.35351045e-02  3.21747884e-02  8.02540407e-03 -2.39106920e-02\n",
      "  -1.21998938e-03  3.14599052e-02 -5.24924174e-02 -8.06814898e-03\n",
      "   3.14770686e-03  5.11496663e-02 -4.44104858e-02  6.36013076e-02\n",
      "   3.85084189e-02  3.30432691e-02 -4.18729289e-03  4.95592505e-02\n",
      "  -5.69604859e-02 -6.49710977e-03 -2.49793567e-02 -1.60867106e-02\n",
      "   6.62289038e-02 -2.06310749e-02  1.08045734e-01  1.68547016e-02\n",
      "   1.43812951e-02 -1.32126845e-02 -1.29387394e-01  6.95216358e-02\n",
      "  -5.55773191e-02 -6.75413609e-02 -5.45820640e-03 -6.13591308e-03\n",
      "   3.90841030e-02 -6.28779680e-02  3.74063328e-02 -1.16571179e-02\n",
      "   1.29150320e-02 -5.52495494e-02  5.16075864e-02 -4.30838391e-03\n",
      "   5.80247417e-02  1.86945125e-02  2.27810536e-02  3.21665928e-02\n",
      "   5.37978746e-02  7.02849180e-02  7.49311969e-02 -8.41775239e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY7E_0io6vll"
   },
   "source": [
    "# **Fill Mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zywPpq7cXs4k",
    "outputId": "49f50ea8-ed5c-4499-d220-dfc8067abdf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.10731099545955658,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello i'm a fashion model.\"},\n",
       " {'score': 0.08774477988481522,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello i'm a role model.\"},\n",
       " {'score': 0.05338403955101967,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello i'm a new model.\"},\n",
       " {'score': 0.04667219892144203,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello i'm a super model.\"},\n",
       " {'score': 0.02709587849676609,\n",
       "  'token': 2986,\n",
       "  'token_str': 'fine',\n",
       "  'sequence': \"hello i'm a fine model.\"}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7ZcZvFu63-u"
   },
   "source": [
    "# **Table Question Answering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qLxOiTpYCyx",
    "outputId": "0ad01c3c-9af6-41e3-8ec7-079211202900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' classic']\n"
     ]
    }
   ],
   "source": [
    "from transformers import TapexTokenizer, BartForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = TapexTokenizer.from_pretrained(\"microsoft/tapex-base-finetuned-wikisql\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"microsoft/tapex-base-finetuned-wikisql\")\n",
    "\n",
    "data = {\n",
    "    \"book_name\": [\"To Kill a Mockingbird\", \"1984\", \"The Great Gatsby\", \"Pride and Prejudice\", \"The Catcher in the Rye\"],\n",
    "    \"category\": [\"Classic\", \"Dystopian\", \"Fiction\", \"Romance\", \"Coming-of-age\"]\n",
    "}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "\n",
    "query = \"Which category does 'To Kill a Mockingbird' belong to?\"\n",
    "encoding = tokenizer(table=table, query=query, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**encoding)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYN7Von88fND"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c14102059e7401ba7139d59ec8d2ee1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "481ce43f81e449d18ce4a65b78be13c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba59990bf1b147d1b0b356456a821b90",
      "placeholder": "​",
      "style": "IPY_MODEL_f89793fdcff44843ab4d53f09d89a8d4",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "6c5ce41abaa54460a78adbf9ba5c1fb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9be3a8125ae947bf830cd664f6507e1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_481ce43f81e449d18ce4a65b78be13c4",
       "IPY_MODEL_b48e0f12879046e8b37f53674991c04d",
       "IPY_MODEL_b21f8a20dc8e48c3ab5e793b964feb2b"
      ],
      "layout": "IPY_MODEL_1c14102059e7401ba7139d59ec8d2ee1"
     }
    },
    "a26b8631ce924dfc8b05daeccee39e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b21f8a20dc8e48c3ab5e793b964feb2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b89b94f23eeb40b6b21d0e504e985eb9",
      "placeholder": "​",
      "style": "IPY_MODEL_a26b8631ce924dfc8b05daeccee39e03",
      "value": " 2/2 [00:31&lt;00:00, 13.48s/it]"
     }
    },
    "b48e0f12879046e8b37f53674991c04d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c5ce41abaa54460a78adbf9ba5c1fb8",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edda4e059df842db8240ab4ee190801e",
      "value": 2
     }
    },
    "b89b94f23eeb40b6b21d0e504e985eb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba59990bf1b147d1b0b356456a821b90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edda4e059df842db8240ab4ee190801e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f89793fdcff44843ab4d53f09d89a8d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
